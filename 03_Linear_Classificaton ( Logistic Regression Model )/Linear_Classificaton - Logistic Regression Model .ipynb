{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c027a45f",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "356eeef1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import core data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import visualization libraries for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import machine learning tools from scikit-learn\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into train/test sets\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # For converting text to numerical features\n",
        "from sklearn.linear_model import LogisticRegression  # For logistic regression classification model\n",
        "from sklearn.metrics import accuracy_score  # For evaluating model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd29afc1",
      "metadata": {},
      "source": [
        "## Load the Dataset\n",
        "\n",
        "Load the women's clothing e-commerce reviews dataset and display the first few rows to understand the data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b168fdde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The First 5 Rows Of The Dataset\n",
            "                                         Review Text  sentiment\n",
            "0  Absolutely wonderful - silky and sexy and comf...          1\n",
            "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
            "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
            "3  This shirt is very flattering to all due to th...          1\n",
            "4  I love tracy reese dresses, but this one is no...         -1\n"
          ]
        }
      ],
      "source": [
        "# Load the women's clothing e-commerce reviews dataset from CSV file\n",
        "# This dataset contains customer review text and sentiment labels (1 for positive, -1 for negative)\n",
        "df = pd.read_csv(\"../womens_clothing_ecommerce_reviews.csv\")\n",
        "\n",
        "# Display the first 5 rows to understand the data structure\n",
        "print(\"The First 5 Rows Of The Dataset\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93b31a2",
      "metadata": {},
      "source": [
        "## Dataset Information\n",
        "\n",
        "Display summary information about the dataset including data types, non-null counts, and memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "97b8b29f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19818 entries, 0 to 19817\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Review Text  19818 non-null  object\n",
            " 1   sentiment    19818 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 309.8+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Display summary information about the dataset\n",
        "# This shows the number of rows, columns, data types, and memory usage\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8f8af6",
      "metadata": {},
      "source": [
        "## Define Features and Target Variable\n",
        "\n",
        "Select the independent variable (Review Text) and dependent variable (sentiment) for our classification model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7832caee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# Define our features (X) and target variable (Y)\n",
        "# X: Independent variable - Customer review text (raw text data)\n",
        "# Y: Dependent variable - Sentiment labels (1 = positive, -1 = negative)\n",
        "# We'll use text classification to predict sentiment based on review content\n",
        "\n",
        "X = df['Review Text']  # Feature variable containing review text\n",
        "Y = df['sentiment']  # Target variable indicating sentiment (positive/negative)\n",
        "\n",
        "# Verify that both are pandas Series objects\n",
        "print(type(X))\n",
        "print(type(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69611ed6",
      "metadata": {},
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "Divide the dataset into training (80%) and testing (20%) sets with stratification to maintain class balance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ffbf1dc3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shapes of Train/Test Datasets:\n",
            "X_train shape: (15854,)\n",
            "Y_train shape: (15854,)\n",
            "X_test shape: (3964,)\n",
            "Y_test shape: (3964,)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training (80%) and testing (20%) sets\n",
        "# random_state=42 ensures reproducibility - we get the same split every time\n",
        "# stratify=Y maintains the proportion of positive/negative reviews in both sets\n",
        "# Training set: Used to train the model\n",
        "# Testing set: Used to evaluate model performance on unseen data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "\n",
        "# stratify=Y explanation:\n",
        "# This ensures that the proportion of classes in Y is maintained in both training and testing sets\n",
        "# Example: If original data has 80% positive and 20% negative, both train/test will have same ratio\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "print(\"\\nShapes of Train/Test Datasets:\")\n",
        "print(\"X_train shape:\", x_train.shape)\n",
        "print(\"Y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", x_test.shape)\n",
        "print(\"Y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed1e873",
      "metadata": {},
      "source": [
        "## Text Vectorization (Bag of Words)\n",
        "\n",
        "Convert text data into numerical feature vectors using CountVectorizer with stop words removal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "69d5d71c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 373991 stored elements and shape (15854, 11897)>\n",
            "  Coords\tValues\n",
            "  (0, 10214)\t1\n",
            "  (0, 2396)\t1\n",
            "  (0, 4805)\t1\n",
            "  (0, 4210)\t1\n",
            "  (0, 3835)\t1\n",
            "  (0, 9289)\t1\n",
            "  (0, 3680)\t1\n",
            "  (0, 4669)\t1\n",
            "  (0, 6980)\t1\n",
            "  (0, 10773)\t1\n",
            "  (0, 7248)\t1\n",
            "  (0, 7409)\t1\n",
            "  (1, 9289)\t1\n",
            "  (1, 2866)\t1\n",
            "  (1, 3454)\t1\n",
            "  (1, 4206)\t1\n",
            "  (1, 1781)\t1\n",
            "  (1, 6221)\t1\n",
            "  (1, 6711)\t1\n",
            "  (1, 8861)\t1\n",
            "  (1, 9671)\t1\n",
            "  (1, 9424)\t1\n",
            "  (1, 11)\t1\n",
            "  (2, 7409)\t1\n",
            "  (2, 3454)\t3\n",
            "  :\t:\n",
            "  (15853, 4805)\t1\n",
            "  (15853, 7596)\t1\n",
            "  (15853, 6257)\t1\n",
            "  (15853, 2390)\t1\n",
            "  (15853, 11495)\t1\n",
            "  (15853, 1602)\t1\n",
            "  (15853, 8053)\t1\n",
            "  (15853, 4742)\t1\n",
            "  (15853, 8467)\t1\n",
            "  (15853, 7829)\t1\n",
            "  (15853, 9466)\t1\n",
            "  (15853, 10594)\t1\n",
            "  (15853, 11408)\t1\n",
            "  (15853, 11414)\t1\n",
            "  (15853, 8195)\t1\n",
            "  (15853, 584)\t1\n",
            "  (15853, 11438)\t1\n",
            "  (15853, 5070)\t1\n",
            "  (15853, 11519)\t1\n",
            "  (15853, 9280)\t1\n",
            "  (15853, 9273)\t1\n",
            "  (15853, 5103)\t1\n",
            "  (15853, 3990)\t1\n",
            "  (15853, 521)\t1\n",
            "  (15853, 4857)\t1\n",
            "(15854, 11897)\n",
            "(3964, 11897)\n"
          ]
        }
      ],
      "source": [
        "# Initialize CountVectorizer to convert text data into numerical feature vectors\n",
        "# CountVectorizer creates a \"Bag of Words\" representation:\n",
        "# Example: [\"this is a sample\", \"another example here\"] -> [[1,1,1,1,0,0,0],[1,0,0,0,1,1,1]]\n",
        "# Vocabulary: { \"this\":0, \"is\":1, \"a\":2, \"sample\":3, \"another\":4, \"example\":5, \"here\":6 }\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english')  # Remove common English stop words\n",
        "# English stop words are common words like \"the\", \"is\", \"in\", \"and\", etc.\n",
        "# These words may not add significant meaning to sentiment analysis\n",
        "\n",
        "# Fit the vectorizer on the training data and transform both train and test data\n",
        "# fit_transform: Learn vocabulary from training data and convert to vectors\n",
        "# transform: Convert test data using the same vocabulary (no new words added)\n",
        "x_train_bow = vectorizer.fit_transform(x_train)\n",
        "x_test_bow = vectorizer.transform(x_test)\n",
        "\n",
        "# Display the sparse matrix representation and shapes\n",
        "# Sparse matrix saves memory by only storing non-zero values\n",
        "print(x_train_bow)\n",
        "print(x_train_bow.shape)  # (15854 reviews, 11897 unique words in vocabulary)\n",
        "print(x_test_bow.shape)   # (3964 reviews, same 11897 unique words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1670961",
      "metadata": {},
      "source": [
        "## Train the Logistic Regression Model\n",
        "\n",
        "Create and train a Logistic Regression classifier for sentiment analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a7ddf09e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Training Completed.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Logistic Regression model\n",
        "# Logistic Regression is a linear classification algorithm that predicts probabilities\n",
        "# solver='saga': Suitable for large datasets and supports L1/L2 regularization\n",
        "# max_iter=5000: Maximum number of iterations to ensure convergence\n",
        "# random_state=42: Ensures reproducibility of results\n",
        "\n",
        "model = LogisticRegression(max_iter=5000, random_state=42, solver='saga')\n",
        "\n",
        "# Train the model on the training data\n",
        "# The model learns the relationship between word frequencies and sentiment\n",
        "# It finds optimal weights for each word to classify reviews as positive or negative\n",
        "model.fit(x_train_bow, y_train)\n",
        "\n",
        "print(\"\\nModel Training Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5208722f",
      "metadata": {},
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "Make predictions on the test set and calculate the accuracy score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b0c110dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracy on Test Set: 92.99%\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "# The model predicts sentiment (1 or -1) for each review in the test set\n",
        "y_pred = model.predict(x_test_bow)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "# Accuracy: Percentage of correctly classified reviews\n",
        "# Formula: (Number of correct predictions) / (Total number of predictions)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02e845f7",
      "metadata": {},
      "source": [
        "## Prepare New Review Data for Prediction\n",
        "\n",
        "Create a set of new, unseen customer reviews to test the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "15953814",
      "metadata": {},
      "outputs": [],
      "source": [
        "# New unseen dataset of customer reviews\n",
        "# These reviews were not part of the training or testing data\n",
        "# We'll use them to demonstrate the model's ability to classify real-world reviews\n",
        "\n",
        "new_reviews = [\n",
        "    \"I absolutely love this dress! The fit is perfect and the material is so soft.\",\n",
        "    \"The shirt shrunk after one wash. Very disappointed with the quality.\",\n",
        "    \"These pants are okay, but I've seen better for the price.\",\n",
        "    \"Fantastic quality and great value for money. Highly recommend!\",\n",
        "    \"The color faded quickly and the fabric feels cheap.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99409cda",
      "metadata": {},
      "source": [
        "## Predict Sentiment for New Reviews\n",
        "\n",
        "Use the trained model to predict sentiment for new customer reviews.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b1f5e635",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions for New Reviews:\n",
            "Review: I absolutely love this dress! The fit is perfect and the material is so soft.\n",
            "Predicted Sentiment: 1\n",
            "\n",
            "Review: The shirt shrunk after one wash. Very disappointed with the quality.\n",
            "Predicted Sentiment: -1\n",
            "\n",
            "Review: These pants are okay, but I've seen better for the price.\n",
            "Predicted Sentiment: 1\n",
            "\n",
            "Review: Fantastic quality and great value for money. Highly recommend!\n",
            "Predicted Sentiment: 1\n",
            "\n",
            "Review: The color faded quickly and the fabric feels cheap.\n",
            "Predicted Sentiment: -1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Transform new reviews using the same vectorizer fitted on training data\n",
        "# This converts the text reviews into the same numerical format (Bag of Words)\n",
        "new_reviews_bow = vectorizer.transform(new_reviews)\n",
        "\n",
        "# Make predictions on the new reviews\n",
        "# The model will classify each review as positive (1) or negative (-1)\n",
        "new_predictions = model.predict(new_reviews_bow)\n",
        "\n",
        "# Display the predictions for each review\n",
        "print(\"\\nPredictions for New Reviews:\")\n",
        "for review, sentiment in zip(new_reviews, new_predictions):\n",
        "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

# üöÄ Google Cloud (Vertex AI) Deployment Guide - Step by Step

‡∂∏‡∑ö Guide ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä ‡∂Ö‡∂¥‡∑í ‡∂∂‡∂Ω‡∂∏‡∑î ‡∂ö‡∑ú‡∑Ñ‡∑ú‡∂∏‡∂Ø **Docker ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂±‡∑ê‡∂≠‡∑î‡∑Ä**, ‡∂î‡∂∫‡∑è‡∂ú‡∑ö Machine Learning model ‡∂ë‡∂ö‡∂ö‡∑ä Google Cloud Platform (GCP) ‡∂ë‡∂ö‡∑ö Vertex AI ‡∑Ñ‡∂ª‡∑Ñ‡∑è deploy ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è. ‡∂Ö‡∂¥‡∑í ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö **Pre-built Containers** ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫‡∂∫‡∑í. ‡∂∏‡∑ö‡∂ö ‡∂≠‡∂∏‡∂∫‡∑í ‡∂Ω‡∑ö‡∑É‡∑í‡∂∏ ‡∑É‡∑Ñ ‡∑Ä‡∑ö‡∂ú‡∑Ä‡∂≠‡∑ä‡∂∏ ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫.

---

## üìã ‡∂Ö‡∂±‡∑ä‡∂≠‡∂ª‡∑ä‡∂ú‡∂≠‡∂∫ (Table of Contents)

1.  [Prerequisites (‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂≠‡∑è)](#1-prerequisites-‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö-‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂≠‡∑è)
2.  [Environment Setup (‡∂¥‡∂ª‡∑í‡∂ú‡∂´‡∂ö‡∂∫ ‡∑É‡∂ö‡∑É‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏)](#2-environment-setup-‡∂¥‡∂ª‡∑í‡∂ú‡∂´‡∂ö‡∂∫-‡∑É‡∂ö‡∑É‡∑è-‡∂ú‡∑ê‡∂±‡∑ì‡∂∏)
3.  [Project Structure ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏](#3-project-structure-‡∂ë‡∂ö-‡∑Ñ‡∂Ø‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏)
4.  [Model Train ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏](#4-model-train-‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
5.  [Google Cloud Storage (GCS) Bucket ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑É‡∑ë‡∂Ø‡∑ì‡∂∏](#5-google-cloud-storage-gcs-bucket-‡∂ë‡∂ö‡∂ö‡∑ä-‡∑É‡∑ë‡∂Ø‡∑ì‡∂∏)
6.  [Vertex AI ‡∑Ä‡∑ô‡∂≠ Model ‡∂ë‡∂ö Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ (Python Code)](#6-vertex-ai-‡∑Ä‡∑ô‡∂≠-model-‡∂ë‡∂ö-deploy-‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
7.  [Method 2: Google Cloud Console (Web UI) ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏](#7-method-2-google-cloud-console-web-ui-‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è-‡∂ö‡∂ª-deploy-‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
8.  [Test ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏](#8-test-‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)

---

## 1. Prerequisites (‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂≠‡∑è)

‡∂∏‡∑î‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂∏‡∑ö ‡∂Ø‡∑ö‡∑Ä‡∂Ω‡∑ä ‡∑Ñ‡∂Ø‡∑è‡∂ú‡∑ô‡∂± ‡∂â‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö.

1.  **Google Cloud Account ‡∂ë‡∂ö‡∂ö‡∑ä**:
    - [Google Cloud Console](https://console.cloud.google.com/) ‡∂ë‡∂ö‡∂ß ‡∂ú‡∑í‡∑Ñ‡∑í‡∂±‡∑ä Gmail ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä log ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±.
    - ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä Account ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂±‡∂∏‡∑ä $300 free credit ‡∑Ñ‡∂∏‡∑ä‡∂∂‡∑Ä‡∑ô‡∂±‡∑Ä‡∑è.

2.  **New Project ‡∂ë‡∂ö‡∂ö‡∑ä Create ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    - Console ‡∂ë‡∂ö‡∑ö ‡∂ã‡∂© ‡∑Ä‡∂∏‡∑ä ‡∂¥‡∑ê‡∂≠‡∑ä‡∂≠‡∑ö ‡∂≠‡∑í‡∂∫‡∑ô‡∂± Project dropdown ‡∂ë‡∂ö click ‡∂ö‡∂ª‡∂Ω‡∑è "New Project" ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±.
    - ‡∂±‡∂∏‡∂ö‡∑ä ‡∂Ø‡∑ô‡∂±‡∑ä‡∂± (‡∂ã‡∂Ø‡∑è: `my-ml-project`).
    - **Project ID** ‡∂ë‡∂ö ‡∂∏‡∂≠‡∂ö ‡∂≠‡∑í‡∂∫‡∑è‡∂ú‡∂±‡∑ä‡∂± (‡∂∏‡∑ö‡∂ö unique ‡∑Ä‡∑ô‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö).

3.  **Billing Enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    - Project ‡∂ë‡∂ö select ‡∂ö‡∂ª‡∂Ω‡∑è, ‡∑Ä‡∂∏‡∑ä ‡∂¥‡∑ê‡∂≠‡∑ä‡∂≠‡∑ö menu ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä "Billing" ‡∑Ä‡∂Ω‡∂ß ‡∂ú‡∑í‡∑Ñ‡∑í‡∂±‡∑ä card details ‡∂Ø‡∑ì‡∂Ω‡∑è billing enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (Free trial ‡∂ë‡∂ö use ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä).

4.  **API Enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    - Search bar ‡∂ë‡∂ö‡∑ö **"Vertex AI API"** ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è search ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂í‡∂ö _Enable_ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
    - ‡∂ä‡∑Ö‡∂ü‡∂ß **"Cloud Storage API"** ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è search ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂í‡∂ö‡∂≠‡∑ä _Enable_ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.

---

## 2. Environment Setup (‡∂¥‡∂ª‡∑í‡∂ú‡∂´‡∂ö‡∂∫ ‡∑É‡∂ö‡∑É‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏)

‡∂î‡∂∫‡∑è‡∂ú‡∑ö local computer ‡∂ë‡∂ö‡∑ö ‡∂∏‡∑ö‡∑Ä‡∑è install ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±.

1.  **Google Cloud SDK (gcloud CLI) Install ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    - [Download gcloud CLI](https://cloud.google.com/sdk/docs/install) ‡∂Ω‡∑í‡∂±‡∑ä‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä ‡∂ú‡∑í‡∑Ñ‡∑í‡∂±‡∑ä install ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±.
    - Install ‡∑Ä‡∑î‡∂±‡∑è‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö terminal ‡∂ë‡∂ö‡∑ö (CMD/Powershell) ‡∂∏‡∑ö command ‡∂ë‡∂ö ‡∂ú‡∑Ñ‡∂Ω‡∑è login ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±:
      ```bash
      gcloud auth login
      ```
    - ‡∂ä‡∑Ö‡∂ü‡∂ß ‡∂î‡∂∫‡∑è‡∂ú‡∑ö project ‡∂ë‡∂ö set ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±:
      ```bash
      gcloud config set project YOUR_PROJECT_ID
      ```
      _( `YOUR_PROJECT_ID` ‡∑Ä‡∑ô‡∂±‡∑î‡∑Ä‡∂ß ‡∂î‡∂∫‡∑è ‡∂ö‡∂Ω‡∑í‡∂±‡∑ä ‡∑Ñ‡∂Ø‡∑è‡∂ú‡∂≠‡∑ä‡∂≠ Project ID ‡∂ë‡∂ö ‡∂Ø‡∑è‡∂±‡∑ä‡∂±)_

2.  **Python Libraries Install ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    ```bash
    pip install google-cloud-aiplatform google-cloud-storage scikit-learn pandas joblib
    ```

---

## 3. Project Structure ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏

‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∑Ä‡∑ê‡∂©‡∑ö‡∂ß folder ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∑è‡∂ú‡∑ô‡∂± ‡∂∏‡∑ö ‡∑Ä‡∑í‡∂Ø‡∑í‡∂∫‡∂ß files ‡∂ß‡∑í‡∂ö ‡∂≠‡∑í‡∂∫‡∑è‡∂ú‡∂±‡∑ä‡∂±.

```text
my-ml-deploy/
‚îú‚îÄ‚îÄ train.py          # Model ‡∂ë‡∂ö train ‡∂ö‡∂ª‡∂± code ‡∂ë‡∂ö
‚îú‚îÄ‚îÄ deploy.py         # Model ‡∂ë‡∂ö GCP ‡∂ë‡∂ö‡∂ß ‡∂∫‡∑Ä‡∂± code ‡∂ë‡∂ö
‚îú‚îÄ‚îÄ test.py           # Deploy ‡∑Ä‡∑î‡∂±‡∑è‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö check ‡∂ö‡∂ª‡∂± code ‡∂ë‡∂ö
‚îî‚îÄ‚îÄ requirements.txt  # (Optional)
```

---

## 4. Model Train ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

‡∂∏‡∑î‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂Ö‡∂¥‡∑í Scikit-learn model ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂Ω‡∑è ‡∂í‡∂ö `model.joblib` ‡∑Ä‡∑í‡∂Ø‡∑í‡∂∫‡∂ß save ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö. Google pre-built containers support ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö `model.joblib`, `model.pkl`, ‡∑Ñ‡∑ù `model.bst` ‡∑Ä‡∂ú‡∑ö formats ‡∑Ä‡∂Ω‡∂ß.

**`train.py`** ‡∑Ü‡∂∫‡∑í‡∂Ω‡∑ä ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±:

```python
# train.py
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import joblib

# 1. Data load ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±
print("Loading data...")
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Model ‡∂ë‡∂ö train ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
print("Training model...")
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# 3. Model ‡∂ë‡∂ö Local save ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±
# ‡∂±‡∂∏ ‡∂Ö‡∂±‡∑í‡∑Ä‡∑è‡∂ª‡∑ä‡∂∫‡∂∫‡∑ô‡∂±‡∑ä‡∂∏ 'model.joblib' ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫‡∑í.
joblib.dump(model, 'model.joblib')

print(f"Model accuracy: {model.score(X_test, y_test):.2f}")
print("‚úÖ Model saved as 'model.joblib'")
```

‡∂∏‡∑ö‡∂ö run ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:

```bash
python train.py
```

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂î‡∂∫‡∑è‡∂ß `model.joblib` ‡∑Ü‡∂∫‡∑í‡∂Ω‡∑ä ‡∂ë‡∂ö ‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑è ‡∂á‡∂≠‡∑í.

---

## 5. Google Cloud Storage (GCS) Bucket ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑É‡∑ë‡∂Ø‡∑ì‡∂∏

‡∂Ö‡∂¥‡∑ö model file ‡∂ë‡∂ö Vertex AI ‡∂ë‡∂ö‡∂ß ‡∂Ø‡∑ô‡∂±‡∑ä‡∂± ‡∂ö‡∂Ω‡∑í‡∂±‡∑ä, ‡∂í‡∂ö Cloud Storage Bucket ‡∂ë‡∂ö‡∂ö ‡∂Ø‡∑è‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö.

1.  **Bucket ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±** (‡∂±‡∂∏ unique ‡∑Ä‡∑ô‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö, ‡∂ã‡∂Ø‡∑è: `my-model-bucket-2024`):

    ```bash
    # us-central1 region ‡∂ë‡∂ö‡∑ö bucket ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑Ä‡∑è
    gsutil mb -l us-central1 gs://YOUR-UNIQUE-BUCKET-NAME
    ```

2.  **Model ‡∂ë‡∂ö Upload ‡∂ö‡∂ª‡∂±‡∑ä‡∂±**:
    ```bash
    gsutil cp model.joblib gs://YOUR-UNIQUE-BUCKET-NAME/model.joblib
    ```

---

## 6. Vertex AI ‡∑Ä‡∑ô‡∂≠ Model ‡∂ë‡∂ö Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∂¥‡∑í Python script ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂Ω‡∑í‡∂∫‡∂Ω‡∑è ‡∂∏‡∑î‡∑Ö‡∑î deployment process ‡∂ë‡∂ö‡∂∏ automate ‡∂ö‡∂ª‡∂∏‡∑î. ‡∂∏‡∑ö script ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±‡∑ö:

1.  Model ‡∂ë‡∂ö Vertex AI Model Registry ‡∂ë‡∂ö‡∂ß upload ‡∂ö‡∂ª‡∂±‡∑Ä‡∑è.
2.  Endpoint ‡∂ë‡∂ö‡∂ö‡∑ä (API URL ‡∂ë‡∂ö‡∂ö‡∑ä) ‡∑Ñ‡∂Ø‡∂±‡∑Ä‡∑è.
3.  Model ‡∂ë‡∂ö ‡∂í Endpoint ‡∂ë‡∂ö‡∂ß connect ‡∂ö‡∂ª‡∂±‡∑Ä‡∑è.

**`deploy.py`** ‡∑Ü‡∂∫‡∑í‡∂Ω‡∑ä ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±:

```python
# deploy.py
from google.cloud import aiplatform

# --- Configuration ---
PROJECT_ID = "YOUR_PROJECT_ID"           # ‡∂î‡∂∫‡∑è‡∂ú‡∑ö Project ID ‡∂ë‡∂ö
BUCKET_NAME = "gs://YOUR-UNIQUE-BUCKET-NAME"  # ‡∂î‡∂∫‡∑è‡∂ú‡∑ö Bucket ‡∂±‡∂∏
REGION = "us-central1"

print("üöÄ Initializing Vertex AI...")
aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)

# 1. Model ‡∂ë‡∂ö Registry ‡∂ë‡∂ö‡∂ß Upload ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
# ‡∂Ö‡∂¥‡∑í ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö Scikit-learn pre-built container ‡∂ë‡∂ö‡∂ö‡∑ä.
print("üì¶ Uploading model to Vertex AI Registry...")

model = aiplatform.Model.upload(
    display_name="iris-model-v1",
    artifact_uri=BUCKET_NAME,  # model.joblib ‡∂≠‡∑í‡∂∫‡∑ô‡∂± bucket folder ‡∂ë‡∂ö
    serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest",
)

print(f"‚úÖ Model Uploaded: {model.resource_name}")

# 2. Endpoint ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑É‡∑ë‡∂Ø‡∑ì‡∂∏
print("üåê Creating Endpoint...")
endpoint = aiplatform.Endpoint.create(
    display_name="iris-endpoint",
)

print(f"‚úÖ Endpoint Created: {endpoint.resource_name}")

# 3. Model ‡∂ë‡∂ö Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
print("üöÄ Deploying model to Endpoint (This takes 10-15 mins)...")
model.deploy(
    endpoint=endpoint,
    deployed_model_display_name="iris-v1",
    machine_type="n1-standard-2",  # Server type ‡∂ë‡∂ö
    min_replica_count=1,
    max_replica_count=1,
)

print("üéâ Deployment Complete!")
print(f"Endpoint Name: {endpoint.resource_name}")
```

‡∂∏‡∑ö‡∂ö run ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:

```bash
python deploy.py
```

> **‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä:** ‡∂∏‡∑ö step ‡∂ë‡∂ö‡∂ß ‡∑Ä‡∑í‡∂±‡∑è‡∂©‡∑í 10-20‡∂ö‡∑ä ‡∑Ä‡∑í‡∂≠‡∂ª ‡∂∫‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä. Console ‡∂ë‡∂ö‡∑ö errors ‡∂Ö‡∑Ä‡∑ú‡∂≠‡∑ä ‡∂∂‡∂Ω‡∂±‡∑ä‡∂± Billing enable ‡∂Ø ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è.

---

## 7. Method 2: Google Cloud Console (Web UI) ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

‡∂î‡∂∫‡∑è‡∂ß Python code ‡∂Ω‡∑í‡∂∫‡∂±‡∑ä‡∂± ‡∂Ö‡∂∏‡∑è‡∂ª‡∑î ‡∂±‡∂∏‡∑ä, ‡∂∏‡∑ö ‡∂î‡∂ö‡∑ä‡∂ö‡∑ú‡∂∏ ‡∂Ø‡∑ö‡∑Ä‡∂Ω‡∑ä Google Cloud Console website ‡∂ë‡∂ö ‡∑Ñ‡∂ª‡∑Ñ‡∑è click ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±‡∂≠‡∑ä ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä.

### Step 1: Model ‡∂ë‡∂ö Bucket ‡∂ë‡∂ö‡∂ß Upload ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

1.  **Google Cloud Console** ‡∂ë‡∂ö‡∑ö ‡∂Ø‡∂ö‡∑î‡∂´‡∑î ‡∂¥‡∑ê‡∂≠‡∑ä‡∂≠‡∑ö menu ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä **Cloud Storage** -> **Buckets** ‡∑Ä‡∂Ω‡∂ß ‡∂∫‡∂±‡∑ä‡∂±.
2.  ‡∂ú‡∑í‡∂∫‡∂¥‡∑è‡∂ª ‡∑Ñ‡∂Ø‡∂¥‡∑î bucket ‡∂ë‡∂ö click ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (‡∑Ñ‡∑ù ‡∂ã‡∂© ‡∂≠‡∑í‡∂∫‡∑ô‡∂± "CREATE" button ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±).
3.  **"UPLOAD FILES"** button ‡∂ë‡∂ö click ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂î‡∂∫‡∑è‡∂ú‡∑ö `model.joblib` file ‡∂ë‡∂ö upload ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.

### Step 2: Vertex AI Model Registry ‡∂ë‡∂ö‡∂ß Import ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

1.  Menu ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä **Vertex AI** -> **Model Registry** ‡∑Ä‡∂Ω‡∂ß ‡∂∫‡∂±‡∑ä‡∂±.
2.  ‡∂ã‡∂© ‡∂≠‡∑í‡∂∫‡∑ô‡∂± **"IMPORT"** button ‡∂ë‡∂ö click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
3.  **"Import as new model"** ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±.
4.  **Name**: ‡∂∏‡∑ú‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂ª‡∑í ‡∂±‡∂∏‡∂ö‡∑ä ‡∂Ø‡∑ô‡∂±‡∑ä‡∂± (‡∂ã‡∂Ø‡∑è: `iris-model-ui`).
5.  **Region**: `us-central1` (‡∑Ñ‡∑ù ‡∂î‡∂∫‡∑è‡∂ú‡∑ö bucket ‡∂ë‡∂ö ‡∂≠‡∑í‡∂∫‡∑ô‡∂± region ‡∂ë‡∂ö) ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±. **CONTINUE** click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
6.  **Model Settings**:
    - **Model framework version**: `scikit-learn` ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±.
    - **Version**: `1.0` (‡∑Ñ‡∑ù ‡∂î‡∂∫‡∑è‡∂ú‡∑ö model ‡∂ë‡∂ö‡∂ß ‡∂ú‡∑ê‡∂Ω‡∂¥‡∑ô‡∂± ‡∂ë‡∂ö).
    - **Pre-built container**: ‡∂∏‡∑ô‡∂∫ auto-fill ‡∑Ä‡∑ô‡∂∫‡∑í.
    - **Model artifact location**: `BROWSE` click ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂î‡∂∫‡∑è‡∂ú‡∑ö bucket ‡∂ë‡∂ö‡∑ö `model.joblib` ‡∂≠‡∑í‡∂∫‡∑ô‡∂± **folder ‡∂ë‡∂ö** select ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (file ‡∂ë‡∂ö ‡∂±‡∑ô‡∑Ä‡∑ô‡∂∫‡∑í, folder ‡∂ë‡∂ö).
7.  **IMPORT** click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.

### Step 3: Endpoint ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂Ω‡∑è Deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

1.  Model ‡∂ë‡∂ö import ‡∑Ä‡∑î‡∂±‡∑è‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö Model Registry list ‡∂ë‡∂ö‡∑ö ‡∂í‡∂ö ‡∂¥‡∑ô‡∂±‡∑ä‡∂±‡∂∫‡∑í. ‡∂í‡∂ö click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
2.  ‡∂ã‡∂© ‡∂≠‡∑í‡∂∫‡∑ô‡∂± **"DEPLOY TO ENDPOINT"** button ‡∂ë‡∂ö click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
3.  **Define your endpoint**:
    - "Create new endpoint" ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±.
    - ‡∂±‡∂∏‡∂ö‡∑ä ‡∂Ø‡∑ô‡∂±‡∑ä‡∂± (‡∂ã‡∂Ø‡∑è: `iris-endpoint-ui`).
    - **CONTINUE** click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
4.  **Model settings**:
    - **Traffic split**: 100% ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±.
    - **Machine type**: `n1-standard-2` (‡∑Ñ‡∑ù ‡∂Ö‡∂©‡∑î ‡∑Ä‡∑í‡∂∫‡∂Ø‡∂∏‡∑ä `e2-standard-2`) ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±.
    - **CONTINUE** -> **DEPLOY** click ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.

‡∑Ä‡∑í‡∂±‡∑è‡∂©‡∑í 10-15‡∂ö‡∑í‡∂±‡∑ä Endpoint ‡∂ë‡∂ö active ‡∑Ä‡∑ô‡∂∫‡∑í! ‡∂ä‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö ‡∂ö‡∂Ω‡∑í‡∂±‡∑ä ‡∑Ä‡∂ú‡∑ö‡∂∏ `test.py` ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä test ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä.

---

## 8. Test ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

Deployment ‡∂ë‡∂ö ‡∂â‡∑Ä‡∂ª ‡∑Ä‡∑î‡∂±‡∑è‡∂∏, ‡∂Ö‡∂¥‡∑í‡∂ß Endpoint ‡∂ë‡∂ö‡∂ß data ‡∂∫‡∑Ä‡∂Ω‡∑è prediction ‡∂ú‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä.

**`test.py`** ‡∑Ü‡∂∫‡∑í‡∂Ω‡∑ä ‡∂ë‡∂ö ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±:

```python
# test.py
from google.cloud import aiplatform

PROJECT_ID = "YOUR_PROJECT_ID"
REGION = "us-central1"
ENDPOINT_NAME = "iris-endpoint" # ‡∂î‡∂∫‡∑è ‡∂ö‡∂Ω‡∑í‡∂±‡∑ä ‡∂Ø‡∑ì‡∂¥‡∑î ‡∂±‡∂∏

aiplatform.init(project=PROJECT_ID, location=REGION)

# Endpoint ‡∂ë‡∂ö ‡∑Ñ‡∑ú‡∂∫‡∑è‡∂ú‡∂±‡∑ä‡∂±
endpoints = aiplatform.Endpoint.list(filter=f'display_name="{ENDPOINT_NAME}"')

if not endpoints:
    print("‚ùå Endpoint not found!")
else:
    endpoint = endpoints[0]
    print(f"‚úÖ Found Endpoint: {endpoint.resource_name}")

    # Test Data (Iris dataset ‡∂ë‡∂ö‡∑ö sample ‡∂ë‡∂ö‡∂ö‡∑ä)
    # [5.1, 3.5, 1.4, 0.2]
    test_instances = [
        [5.1, 3.5, 1.4, 0.2],
        [6.7, 3.0, 5.2, 2.3]
    ]

    print("üîÆ Sending prediction request...")
    prediction = endpoint.predict(instances=test_instances)

    print("--- Predictions ---")
    print(prediction.predictions)
```

Run ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:

```bash
python test.py
```

‡∂î‡∂∫‡∑è‡∂ß `[0, 2]` ‡∑Ä‡∂ú‡∑ö prediction ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ë‡∂±‡∑Ä‡∑è ‡∂±‡∂∏‡∑ä ‡∑Ä‡∑ê‡∂©‡∑ö ‡∑Ñ‡∂ª‡∑í‡∂∫‡∂ß‡∂∏ ‡∑Ñ‡∂ª‡∑í! ü•≥

---

### üî• Clean Up (‡∑Ä‡∑í‡∂∫‡∂Ø‡∂∏‡∑ä ‡∂Ö‡∂©‡∑î ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±)

‡∑Ä‡∑ê‡∂©‡∑ö ‡∂â‡∑Ä‡∂ª ‡∑Ä‡∑î‡∂±‡∑è‡∂∏ Endpoint ‡∂ë‡∂ö delete ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂Ö‡∂∏‡∂≠‡∂ö ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ë‡∂¥‡∑è, ‡∂±‡∑ê‡∂≠‡∑ä‡∂±‡∂∏‡∑ä ‡∂Ø‡∑í‡∂ú‡∂ß‡∂∏ ‡∑É‡∂Ω‡∑ä‡∂Ω‡∑í ‡∂ö‡∑ê‡∂¥‡∑ô‡∂±‡∑Ä‡∑è.

```python
# python console ‡∂ë‡∂ö‡∑ö ‡∂ú‡∑Ñ‡∂±‡∑ä‡∂±
endpoint.undeploy_all()
endpoint.delete()
```

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b63baad",
   "metadata": {},
   "source": [
    "# üöÄ Deploy Pipeline to Vertex AI - Example Template\n",
    "\n",
    "This is an example template for deploying ML pipelines to Google Cloud Vertex AI.\n",
    "\n",
    "**üîê Setup Instructions:**\n",
    "\n",
    "1. Copy this notebook and remove `.example` from the filename\n",
    "2. Configure your GCP project using `config.py` or direct configuration\n",
    "3. Complete the prerequisites below\n",
    "4. Run the deployment cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00181d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure:\n",
    "\n",
    "1. ‚úÖ Pipeline ‡∂ë‡∂ö train ‡∂ö‡∂ª‡∂Ω‡∑è `model.joblib` ‡∑Ä‡∑í‡∂Ø‡∑í‡∂∫‡∂ß save ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö\n",
    "2. ‚úÖ Google Cloud Project ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂Ω‡∑è billing enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "3. ‚úÖ Vertex AI API ‡∑É‡∑Ñ Cloud Storage API enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "4. ‚úÖ Authentication ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±: `gcloud auth application-default login`\n",
    "\n",
    "### Enable Required APIs:\n",
    "\n",
    "```bash\n",
    "gcloud services enable aiplatform.googleapis.com\n",
    "gcloud services enable storage.googleapis.com\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d76fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from google.cloud import aiplatform, storage\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355a09c",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Option 1: Use .env file (Recommended)**\n",
    "\n",
    "1. Copy `.env.example` to `.env` in **this directory** (07_Pipeline_Deployment/)\n",
    "\n",
    "2. Edit `.env` with your GCP project detailsFill in values directly in the second cell\n",
    "\n",
    "3. Run the config cell below\n",
    "\n",
    "**Option 2: Direct Configuration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load from local config.py (which loads from .env)\n",
    "try:\n",
    "    from config import (GCP_PROJECT_ID, GCP_REGION, GCS_BUCKET_NAME,\n",
    "                       ENDPOINT_DISPLAY_NAME, MODEL_DISPLAY_NAME, LOCAL_MODEL_PATH)\n",
    "\n",
    "    PROJECT_ID = GCP_PROJECT_ID\n",
    "    REGION = GCP_REGION\n",
    "    BUCKET_NAME = GCS_BUCKET_NAME\n",
    "\n",
    "    print(\"‚úÖ Configuration loaded from config.py\")\n",
    "    print(f\"Project: {PROJECT_ID}\")\n",
    "    print(f\"Region: {REGION}\")\n",
    "    print(f\"Bucket: gs://{BUCKET_NAME}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è config.py not found in this directory.\")\n",
    "    print(\"Please create .env file (copy from .env.example) or use Option 2 below.\")\n",
    "    PROJECT_ID = None\n",
    "    REGION = None\n",
    "    BUCKET_NAME = None\n",
    "\n",
    "    ENDPOINT_DISPLAY_NAME = None    LOCAL_MODEL_PATH = \"model.joblib\"\n",
    "    MODEL_DISPLAY_NAME = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Direct Configuration (uncomment and fill in)\n",
    "\n",
    "# PROJECT_ID = \"your-project-id-here\"  # Your GCP Project ID\n",
    "# REGION = \"us-central1\"  # e.g., us-central1, asia-southeast1\n",
    "# BUCKET_NAME = \"your-bucket-name\"  # GCS bucket name (WITHOUT gs:// prefix)\n",
    "# MODEL_DISPLAY_NAME = \"sentiment-pipeline-model\"  # Name for your model\n",
    "# ENDPOINT_DISPLAY_NAME = \"sentiment-endpoint\"  # Name for your endpoint\n",
    "# LOCAL_MODEL_PATH = \"model.joblib\"  # The pipeline file\n",
    "\n",
    "if 'LOCAL_MODEL_PATH' not in locals():\n",
    "    LOCAL_MODEL_PATH = \"model.joblib\"\n",
    "\n",
    "# Print configuration\n",
    "if PROJECT_ID and PROJECT_ID not in [\"YOUR_PROJECT_ID\", \"your-project-id-here\"]:\n",
    "    print(f\"‚úÖ Project: {PROJECT_ID}\")\n",
    "    print(f\"‚úÖ Region: {REGION}\")\n",
    "    print(f\"‚úÖ Bucket: gs://{BUCKET_NAME}\")\n",
    "    print(f\"‚úÖ Model file: {LOCAL_MODEL_PATH}\")\n",
    "else:\n",
    "    print(\"‚ùå Please configure PROJECT_ID, REGION, and BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6da21e",
   "metadata": {},
   "source": [
    "## Step 1: Create GCS Bucket (Optional)\n",
    "\n",
    "Run this only if you need to create a new bucket:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9da44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GCS Bucket (uncomment if you need to create one)\n",
    "if PROJECT_ID and PROJECT_ID not in [\"YOUR_PROJECT_ID\", \"your-project-id-here\"]:\n",
    "    # Uncomment the lines below to create a bucket\n",
    "    # storage_client = storage.Client(project=PROJECT_ID)\n",
    "    # try:\n",
    "    #     bucket = storage_client.create_bucket(BUCKET_NAME, location=REGION)\n",
    "    #     print(f\"‚úÖ Bucket {bucket.name} created in {REGION}\")\n",
    "    # except Exception as e:\n",
    "    #     if \"already exists\" in str(e):\n",
    "    #         print(f\"‚úÖ Bucket {BUCKET_NAME} already exists\")\n",
    "    #     else:\n",
    "    #         print(f\"‚ùå Error: {e}\")\n",
    "    print(\"üí° Bucket creation code is commented out. Uncomment if needed.\")\n",
    "else:\n",
    "    print(\"‚ùå Please configure your project first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb92c1e",
   "metadata": {},
   "source": [
    "## Step 2: Upload Pipeline to GCS\n",
    "\n",
    "Upload your `model.joblib` (which contains the complete pipeline) to Google Cloud Storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb89706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model.joblib to GCS bucket\n",
    "if PROJECT_ID and PROJECT_ID not in [\"YOUR_PROJECT_ID\", \"your-project-id-here\"]:\n",
    "    try:\n",
    "        storage_client = storage.Client(project=PROJECT_ID)\n",
    "        bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "        # Create a folder structure: model/model.joblib\n",
    "        blob = bucket.blob(\"model/model.joblib\")\n",
    "\n",
    "        # Upload the file\n",
    "        print(\"üì§ Uploading pipeline to GCS...\")\n",
    "        blob.upload_from_filename(LOCAL_MODEL_PATH)\n",
    "\n",
    "        print(f\"‚úÖ Pipeline uploaded to: gs://{BUCKET_NAME}/model/model.joblib\")\n",
    "\n",
    "        # This is the artifact URI you'll use for deployment\n",
    "        ARTIFACT_URI = f\"gs://{BUCKET_NAME}/model\"\n",
    "        print(f\"üìç Artifact URI: {ARTIFACT_URI}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {LOCAL_MODEL_PATH}\")\n",
    "        print(\"Make sure you trained and saved the model first!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Please configure your project first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e531403",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Vertex AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "if PROJECT_ID and PROJECT_ID not in [\"YOUR_PROJECT_ID\", \"your-project-id-here\"]:\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "    print(\"‚úÖ Vertex AI initialized\")\n",
    "else:\n",
    "    print(\"‚ùå Please configure your project first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f040fc4",
   "metadata": {},
   "source": [
    "## Step 4: Upload Model to Vertex AI Registry\n",
    "\n",
    "Register your pipeline in Vertex AI Model Registry:\n",
    "\n",
    "**Important:** Choose the correct scikit-learn container version!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to Vertex AI Model Registry\n",
    "if 'ARTIFACT_URI' in locals():\n",
    "    print(\"üì¶ Uploading model to Vertex AI Registry...\")\n",
    "    print(\"‚è≥ This may take 5-10 minutes...\")\n",
    "\n",
    "    try:\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name=MODEL_DISPLAY_NAME,\n",
    "            artifact_uri=ARTIFACT_URI,\n",
    "            serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "            # For different sklearn versions, use:\n",
    "            # sklearn 1.0: \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\"\n",
    "            # sklearn 1.2: \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\"\n",
    "            # sklearn 1.3: \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest\"\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Model uploaded successfully!\")\n",
    "        print(f\"Model resource name: {model.resource_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Pipeline not uploaded to GCS yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ed323",
   "metadata": {},
   "source": [
    "## Step 5: Deploy to Endpoint\n",
    "\n",
    "Use an existing endpoint or create a new one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8792821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create endpoint\n",
    "if 'model' in locals():\n",
    "    try:\n",
    "        # Option A: Use existing endpoint\n",
    "        print(\"üîç Looking for existing endpoint...\")\n",
    "        endpoints = aiplatform.Endpoint.list(filter=f'display_name=\"{ENDPOINT_DISPLAY_NAME}\"')\n",
    "\n",
    "        if endpoints:\n",
    "            endpoint = endpoints[0]\n",
    "            print(f\"‚úÖ Found existing endpoint: {endpoint.display_name}\")\n",
    "            print(f\"Resource name: {endpoint.resource_name}\")\n",
    "        else:\n",
    "            # Option B: Create new endpoint if not found\n",
    "            print(\"Creating new endpoint...\")\n",
    "            endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "            print(f\"‚úÖ Endpoint created: {endpoint.display_name}\")\n",
    "\n",
    "        print(f\"\\nüìç Endpoint resource: {endpoint.resource_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Model not uploaded yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to endpoint\n",
    "if 'endpoint' in locals() and 'model' in locals():\n",
    "    print(\"üöÄ Deploying model to endpoint...\")\n",
    "    print(\"‚è≥ This will take 10-15 minutes...\")\n",
    "\n",
    "    try:\n",
    "        model.deploy(\n",
    "            endpoint=endpoint,\n",
    "            deployed_model_display_name=f\"{MODEL_DISPLAY_NAME}-deployed\",\n",
    "            machine_type=\"n1-standard-2\",  # You can use n1-standard-4 for more power\n",
    "            min_replica_count=1,\n",
    "            max_replica_count=1,\n",
    "            traffic_percentage=100,  # Route 100% traffic to this version\n",
    "        )\n",
    "\n",
    "        print(\"\\nüéâ Deployment completed successfully!\")\n",
    "        print(f\"‚úÖ Endpoint: {endpoint.display_name}\")\n",
    "        print(f\"‚úÖ Resource: {endpoint.resource_name}\")\n",
    "        print(\"\\nüí° Now you can send RAW TEXT directly to get predictions!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Endpoint or model not ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4741d86",
   "metadata": {},
   "source": [
    "## Step 6: Test with Raw Text\n",
    "\n",
    "Now you can send raw text directly without a vectorizer!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with raw text\n",
    "if 'endpoint' in locals():\n",
    "    new_review = \"I recently purchased this dress and I have to say, it exceeded my expectations!\"\n",
    "\n",
    "    print(f\"Testing with review: '{new_review}'\")\n",
    "    print(\"\\n...Calling endpoint...\")\n",
    "\n",
    "    try:\n",
    "        # Send raw text directly - no vectorizer needed!\n",
    "        response = endpoint.predict(instances=[new_review])\n",
    "\n",
    "        print(\"\\n--- Prediction Result ---\")\n",
    "        print(f\"Prediction: {response.predictions[0]}\")\n",
    "\n",
    "        if response.predictions[0] == 1:\n",
    "            print(\"üìä Classification: POSITIVE review ‚úì\")\n",
    "        else:\n",
    "            print(\"üìä Classification: NEGATIVE review ‚úó\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Endpoint not ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa58908",
   "metadata": {},
   "source": [
    "## Step 7: Test with Multiple Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple reviews\n",
    "if 'endpoint' in locals():\n",
    "    test_reviews = [\n",
    "        \"I absolutely love this dress! The fit is perfect and the material is so soft.\",\n",
    "        \"The shirt shrunk after one wash. Very disappointed with the quality.\",\n",
    "        \"Amazing product! Highly recommend to everyone!\",\n",
    "        \"Terrible quality. Waste of money.\"\n",
    "    ]\n",
    "\n",
    "    print(\"Testing multiple reviews...\\n\")\n",
    "\n",
    "    try:\n",
    "        for i, review in enumerate(test_reviews, 1):\n",
    "            response = endpoint.predict(instances=[review])\n",
    "            sentiment = \"POSITIVE ‚úì\" if response.predictions[0] == 1 else \"NEGATIVE ‚úó\"\n",
    "            print(f\"{i}. {review}\")\n",
    "            print(f\"   ‚Üí {sentiment}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Endpoint not ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141736a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Success!\n",
    "\n",
    "### You now have:\n",
    "\n",
    "‚úÖ Pipeline (vectorizer + model) deployed to Vertex AI  \n",
    "‚úÖ Ability to send raw text directly to endpoint  \n",
    "‚úÖ No need to load vectorizer locally  \n",
    "‚úÖ Production-ready deployment\n",
    "\n",
    "### Useful Commands:\n",
    "\n",
    "```python\n",
    "# List all models\n",
    "models = aiplatform.Model.list()\n",
    "for m in models:\n",
    "    print(m.display_name)\n",
    "\n",
    "# List all endpoints\n",
    "endpoints = aiplatform.Endpoint.list()\n",
    "for ep in endpoints:\n",
    "    print(ep.display_name)\n",
    "\n",
    "# Undeploy old version\n",
    "# endpoint.undeploy_all()\n",
    "\n",
    "# Delete endpoint (careful!)\n",
    "# endpoint.delete()\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Test your endpoint using `08_Hit_Pipeline_Deployment/08_Pipeline_Deployment.ipynb`\n",
    "2. Integrate with your application\n",
    "3. Monitor performance in Google Cloud Console\n",
    "4. Set up logging and monitoring\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe9c674",
   "metadata": {},
   "source": [
    "# üöÄ Deploy Pipeline to Vertex AI - Complete Guide\n",
    "\n",
    "‡∂∏‡∑ô‡∂∏ notebook ‡∂ë‡∂ö ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂Ω‡∑è **complete pipeline** (vectorizer + model) Vertex AI ‡∂ë‡∂ö‡∂ß deploy ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä.\n",
    "\n",
    "**‡∂∏‡∑ô‡∂≠‡∂±‡∂Ø‡∑ì ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±‡∑ö:**\n",
    "\n",
    "1. Pipeline ‡∂ë‡∂ö GCS Bucket ‡∂ë‡∂ö‡∂ß upload ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏\n",
    "2. Vertex AI Model Registry ‡∂ë‡∂ö‡∂ß register ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏\n",
    "3. Endpoint ‡∂ë‡∂ö‡∂ö‡∑ä create ‡∂ö‡∂ª‡∂Ω‡∑è deploy ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏\n",
    "4. Raw text ‡∂∫‡∑Ä‡∂Ω‡∑è predictions ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏ (vectorizer ‡∂±‡∑ê‡∂≠‡∑î‡∑Ä!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac2ce7",
   "metadata": {},
   "source": [
    "## Prerequisites (‡∂¥‡∑Ö‡∂∏‡∑î‡∑Ä ‡∂∏‡∑ö‡∑Ä‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±)\n",
    "\n",
    "1. ‚úÖ Pipeline ‡∂ë‡∂ö train ‡∂ö‡∂ª‡∂Ω‡∑è `model.joblib` ‡∑Ä‡∑í‡∂Ø‡∑í‡∂∫‡∂ß save ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö\n",
    "2. ‚úÖ Google Cloud Project ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂Ω‡∑è billing enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "3. ‚úÖ Vertex AI API ‡∑É‡∑Ñ Cloud Storage API enable ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "4. ‚úÖ Authentication ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±: `gcloud auth application-default login`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from google.cloud import aiplatform, storage\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef007fd",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "‡∂î‡∂∂‡∂ú‡∑ö Project details fill ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b14df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "PROJECT_ID = \"project-968ac48e-8511-4620-9fe\"  # Your Project ID\n",
    "REGION = \"asia-southeast1\"  # Singapore region\n",
    "BUCKET_NAME = \"your-bucket-name\"  # GCS bucket name (WITHOUT gs:// prefix)\n",
    "\n",
    "# Model details\n",
    "MODEL_DISPLAY_NAME = \"sentiment-pipeline-v2\"  # New name for pipeline deployment\n",
    "ENDPOINT_DISPLAY_NAME = \"Pipeline_Deployment\"  # Your existing endpoint name\n",
    "\n",
    "# Local file path\n",
    "LOCAL_MODEL_PATH = \"model.joblib\"  # The pipeline file\n",
    "\n",
    "print(f\"‚úÖ Project: {PROJECT_ID}\")\n",
    "print(f\"‚úÖ Region: {REGION}\")\n",
    "print(f\"‚úÖ Bucket: gs://{BUCKET_NAME}\")\n",
    "print(f\"‚úÖ Model file: {LOCAL_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea8c1f",
   "metadata": {},
   "source": [
    "## Step 2: Create GCS Bucket (if needed)\n",
    "\n",
    "Bucket ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂±‡∑ê‡∂≠‡∑ä‡∂±‡∂∏‡∑ä ‡∂∏‡∑ö‡∂ö run ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GCS Bucket (uncomment if you need to create one)\n",
    "# storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# try:\n",
    "#     bucket = storage_client.create_bucket(BUCKET_NAME, location=REGION)\n",
    "#     print(f\"‚úÖ Bucket {bucket.name} created in {REGION}\")\n",
    "# except Exception as e:\n",
    "#     if \"already exists\" in str(e):\n",
    "#         print(f\"‚úÖ Bucket {BUCKET_NAME} already exists\")\n",
    "#     else:\n",
    "#         print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e5860",
   "metadata": {},
   "source": [
    "## Step 3: Upload Pipeline to GCS\n",
    "\n",
    "Pipeline ‡∂ë‡∂ö (model.joblib) bucket ‡∂ë‡∂ö‡∂ß upload ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model.joblib to GCS bucket\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Create a folder structure: model/model.joblib\n",
    "blob = bucket.blob(\"model/model.joblib\")\n",
    "\n",
    "# Upload the file\n",
    "print(\"üì§ Uploading pipeline to GCS...\")\n",
    "blob.upload_from_filename(LOCAL_MODEL_PATH)\n",
    "\n",
    "print(f\"‚úÖ Pipeline uploaded to: gs://{BUCKET_NAME}/model/model.joblib\")\n",
    "\n",
    "# This is the artifact URI you'll use for deployment\n",
    "ARTIFACT_URI = f\"gs://{BUCKET_NAME}/model\"\n",
    "print(f\"üìç Artifact URI: {ARTIFACT_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413656f",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Vertex AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "print(\"‚úÖ Vertex AI initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f05106",
   "metadata": {},
   "source": [
    "## Step 5: Upload Model to Vertex AI Registry\n",
    "\n",
    "Pipeline ‡∂ë‡∂ö Vertex AI Model Registry ‡∂ë‡∂ö‡∂ß register ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:\n",
    "\n",
    "**‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä:** Scikit-learn version ‡∂ë‡∂ö ‡∑Ñ‡∂ª‡∑í container ‡∂ë‡∂ö ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc48b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to Vertex AI Model Registry\n",
    "print(\"üì¶ Uploading model to Vertex AI Registry...\")\n",
    "print(\"‚è≥ This may take 5-10 minutes...\")\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "    # For different sklearn versions, use:\n",
    "    # sklearn 1.2: \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\"\n",
    "    # sklearn 1.3: \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model uploaded successfully!\")\n",
    "print(f\"Model resource name: {model.resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a413b",
   "metadata": {},
   "source": [
    "## Step 6: Deploy to Endpoint\n",
    "\n",
    "‡∂Ø‡∑ê‡∂±‡∂ß ‡∂≠‡∑í‡∂∫‡∑ô‡∂± endpoint ‡∂ë‡∂ö use ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∑Ñ‡∑ù ‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂±:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22964f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Use existing endpoint\n",
    "print(\"üîç Looking for existing endpoint...\")\n",
    "endpoints = aiplatform.Endpoint.list(filter=f'display_name=\"{ENDPOINT_DISPLAY_NAME}\"')\n",
    "\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"‚úÖ Found existing endpoint: {endpoint.display_name}\")\n",
    "    print(f\"Resource name: {endpoint.resource_name}\")\n",
    "else:\n",
    "    # Option B: Create new endpoint if not found\n",
    "    print(\"Creating new endpoint...\")\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "    print(f\"‚úÖ Endpoint created: {endpoint.display_name}\")\n",
    "\n",
    "print(f\"\\nüìç Endpoint resource: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to endpoint\n",
    "print(\"üöÄ Deploying model to endpoint...\")\n",
    "print(\"‚è≥ This will take 10-15 minutes...\")\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=\"pipeline-v2\",\n",
    "    machine_type=\"n1-standard-2\",  # You can use n1-standard-4 for more power\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    traffic_percentage=100,  # Route 100% traffic to this version\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Deployment completed successfully!\")\n",
    "print(f\"‚úÖ Endpoint: {endpoint.display_name}\")\n",
    "print(f\"‚úÖ Resource: {endpoint.resource_name}\")\n",
    "print(\"\\nüí° Now you can send RAW TEXT directly to get predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445740db",
   "metadata": {},
   "source": [
    "## Step 7: Test with Raw Text\n",
    "\n",
    "‡∂Ø‡∑ê‡∂±‡∑ä vectorizer ‡∂±‡∑ê‡∂≠‡∑î‡∑Ä ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ raw text ‡∂∫‡∑Ä‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c569c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with raw text\n",
    "new_review = \"I recently purchased this dress and I have to say, it exceeded my expectations!\"\n",
    "\n",
    "print(f\"Testing with review: '{new_review}'\")\n",
    "print(\"\\n...Calling endpoint...\")\n",
    "\n",
    "# Send raw text directly - no vectorizer needed!\n",
    "response = endpoint.predict(instances=[new_review])\n",
    "\n",
    "print(\"\\n--- Prediction Result ---\")\n",
    "print(f\"Prediction: {response.predictions[0]}\")\n",
    "\n",
    "if response.predictions[0] == 1:\n",
    "    print(\"üìä Classification: POSITIVE review ‚úì\")\n",
    "else:\n",
    "    print(\"üìä Classification: NEGATIVE review ‚úó\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded802d",
   "metadata": {},
   "source": [
    "## Step 8: Test with Multiple Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be23a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple reviews\n",
    "test_reviews = [\n",
    "    \"I absolutely love this dress! The fit is perfect and the material is so soft.\",\n",
    "    \"The shirt shrunk after one wash. Very disappointed with the quality.\",\n",
    "    \"Amazing product! Highly recommend to everyone!\",\n",
    "    \"Terrible quality. Waste of money.\"\n",
    "]\n",
    "\n",
    "print(\"Testing multiple reviews...\\n\")\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    response = endpoint.predict(instances=[review])\n",
    "    sentiment = \"POSITIVE ‚úì\" if response.predictions[0] == 1 else \"NEGATIVE ‚úó\"\n",
    "    print(f\"{i}. {review}\")\n",
    "    print(f\"   ‚Üí {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec11535",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "### ‡∑Ä‡∑í‡∂¢‡∂∫‡∂ú‡∑í‡∂∫!\n",
    "\n",
    "‡∂Ø‡∑ê‡∂±‡∑ä ‡∂î‡∂∂‡∂ß:\n",
    "\n",
    "‚úÖ Pipeline (vectorizer + model) Vertex AI ‡∂ë‡∂ö‡∂ß deploy ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è  \n",
    "‚úÖ Raw text ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ endpoint ‡∂ë‡∂ö‡∂ß ‡∂∫‡∑Ä‡∂±‡∑ä‡∂± ‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä  \n",
    "‚úÖ Vectorizer ‡∂ë‡∂ö locally load ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∂±‡∑ê‡∑Ñ‡∑ê  \n",
    "‚úÖ Production-ready deployment ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è\n",
    "\n",
    "### Useful Commands:\n",
    "\n",
    "```python\n",
    "# List all models\n",
    "models = aiplatform.Model.list()\n",
    "\n",
    "# List all endpoints\n",
    "endpoints = aiplatform.Endpoint.list()\n",
    "\n",
    "# Undeploy old version\n",
    "# endpoint.undeploy_all()\n",
    "\n",
    "# Delete endpoint\n",
    "# endpoint.delete()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

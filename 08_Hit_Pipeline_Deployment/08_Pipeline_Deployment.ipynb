{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# Get Online Inference from Vertex AI Endpoint\n",
        "\n",
        "This notebook demonstrates how to get predictions from a deployed Vertex AI Endpoint.\n",
        "Make sure you have authenticated with Google Cloud before running this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import Required Libraries\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2cf47df9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\chamm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\auth\\_default.py:114: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using existing credentials\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Google Cloud\n",
        "# This will open a browser window for you to sign in\n",
        "import google.auth\n",
        "\n",
        "try:\n",
        "    # Try to get default credentials\n",
        "    credentials, project = google.auth.default()\n",
        "    print(\"‚úÖ Using existing credentials\")\n",
        "except:\n",
        "    # If no credentials found, use gcloud auth\n",
        "    print(\"‚ö†Ô∏è No credentials found. Please authenticate using one of these methods:\\n\")\n",
        "    print(\"Method 1 (Recommended for local development):\")\n",
        "    print(\"   Run in terminal: gcloud auth application-default login\\n\")\n",
        "    print(\"Method 2 (For Colab):\")\n",
        "    print(\"   from google.colab import auth\")\n",
        "    print(\"   auth.authenticate_user()\\n\")\n",
        "    print(\"Method 3 (Service Account):\")\n",
        "    print(\"   Set environment variable: GOOGLE_APPLICATION_CREDENTIALS=path/to/key.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ff5a44",
      "metadata": {},
      "source": [
        "## Authenticate with Google Cloud\n",
        "\n",
        "**Important:** Run this cell first to authenticate with Google Cloud.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config_md",
      "metadata": {},
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Please fill in your Project ID, Region, and the Display Name of your Endpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "config_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project: project-968ac48e-8511-4620-9fe\n",
            "Region: asia-southeast1\n",
            "Endpoint Name: Pipeline_Deployment_Model_Endpoint\n"
          ]
        }
      ],
      "source": [
        "# --- TODO: Update these values ---\n",
        "# Use the PROJECT_ID from 'gcloud projects list' command\n",
        "# Based on your projects, likely one of these:\n",
        "# - \"dasun-487410\"\n",
        "# - \"enterprise-cloud-architecture\"\n",
        "# - \"project-968ac48e-8511-4620-9fe\" (Chamath - Logistic Model)\n",
        "\n",
        "PROJECT_ID = \"project-968ac48e-8511-4620-9fe\"  # Update this with your actual project ID\n",
        "REGION = \"asia-southeast1\"  # Singapore region\n",
        "ENDPOINT_DISPLAY_NAME = \"Pipeline_Deployment_Model_Endpoint\" # The name you gave your endpoint\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}\")\n",
        "print(f\"Region: {REGION}\")\n",
        "print(f\"Endpoint Name: {ENDPOINT_DISPLAY_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "init_sdk",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vertex AI SDK Initialized.\n"
          ]
        }
      ],
      "source": [
        "## 2. Initialize Vertex AI SDK\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "print(\"Vertex AI SDK Initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "get_endpoint",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found Endpoint: projects/994556670658/locations/asia-southeast1/endpoints/8290495794314739712\n"
          ]
        }
      ],
      "source": [
        "## 3. Get Endpoint Object\n",
        "# Look up the endpoint by its display name\n",
        "try:\n",
        "    endpoints = aiplatform.Endpoint.list(filter=f'display_name=\"{ENDPOINT_DISPLAY_NAME}\"')\n",
        "\n",
        "    if endpoints:\n",
        "        endpoint = endpoints[0]\n",
        "        print(f\"‚úÖ Found Endpoint: {endpoint.resource_name}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Endpoint '{ENDPOINT_DISPLAY_NAME}' not found in region {REGION}.\")\n",
        "        print(\"Please check the name and region.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error accessing endpoint: {str(e)}\")\n",
        "    print(\"\\nCommon issues:\")\n",
        "    print(\"1. Authentication: Run 'gcloud auth application-default login' in terminal\")\n",
        "    print(\"2. Project ID: Make sure you're using the project ID (name), not project number\")\n",
        "    print(\"3. Permissions: Ensure you have Vertex AI User role\")\n",
        "    print(\"4. API: Enable Vertex AI API in your project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cd29480e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 4. Load Vectorizer and Prepare Data\n",
        "# # Load the vectorizer that was used to train the model\n",
        "# print(\"Loading vectorizer...\")\n",
        "# vectorizer = joblib.load(\"../07_Pipeline_Deployment/vectorizer.joblib\")\n",
        "# print(\"‚úÖ Vectorizer loaded successfully\")\n",
        "\n",
        "# # --- THE NEW DATA ---\n",
        "# # This is the new, raw text review we want to classify.\n",
        "# new_review = \"I recently purchased this dress and I have to say, it exceeded my expectations!\"\n",
        "# print(f\"\\nOriginal review: '{new_review}'\")\n",
        "\n",
        "# # --- PREPROCESS THE TEXT ---\n",
        "# # Transform the text into numeric features using the vectorizer\n",
        "# print(\"\\nPreprocessing text...\")\n",
        "# sparse_matrix = vectorizer.transform([new_review])\n",
        "\n",
        "# # Convert sparse matrix to dense array and then to list (Vertex AI expects lists)\n",
        "# prediction_instances = sparse_matrix.toarray().tolist()\n",
        "# print(f\"‚úÖ Text vectorized - Shape: {sparse_matrix.shape}\")\n",
        "\n",
        "# # --- MAKE THE PREDICTION CALL ---\n",
        "# print(\"\\n...Calling the endpoint...\")\n",
        "# response = endpoint.predict(instances=prediction_instances)\n",
        "\n",
        "# print(\"\\n--- Prediction Result ---\")\n",
        "# print(f\"Prediction: {response.predictions}\")\n",
        "\n",
        "# # Interpret the result\n",
        "# if response.predictions[0] == 1:\n",
        "#     print(\"üìä Classification: POSITIVE review ‚úì\")\n",
        "# else:\n",
        "#     print(\"üìä Classification: NEGATIVE review ‚úó\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25906799",
      "metadata": {},
      "source": [
        "## üìå Important Note: Pipeline vs Model-Only Deployment\n",
        "\n",
        "**‡∂î‡∂∂ ‡∑Ñ‡∂ª‡∑í!** If you deployed the **complete Pipeline** (pipeline.joblib), you should send raw text directly.\n",
        "\n",
        "However, based on the errors we received:\n",
        "\n",
        "- `dtype='numeric' is not compatible with arrays of bytes/strings`\n",
        "\n",
        "This indicates the deployed model is **only the model** (model.joblib), not the pipeline.\n",
        "\n",
        "**Two Solutions:**\n",
        "\n",
        "1. **Current approach** (above): Load vectorizer locally and transform text before sending\n",
        "2. **Better approach**: Redeploy using `pipeline.joblib` instead, then send raw text directly\n",
        "\n",
        "If you want to try sending raw text (to test if pipeline was deployed), use the cell below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9ada732d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with raw text: 'I recently purchased this dress and I have to say, it exceeded my expectations!'\n",
            "\n",
            "...Calling the endpoint with raw text...\n",
            "\n",
            "‚úÖ SUCCESS! Pipeline was deployed - raw text works!\n",
            "Prediction: [1.0]\n",
            "üìä Classification: POSITIVE review ‚úì\n"
          ]
        }
      ],
      "source": [
        "# 5. TEST: Try sending raw text (if pipeline was deployed)\n",
        "\n",
        "new_review_raw = [\"I recently purchased this dress and I have to say, it exceeded my expectations!\"]\n",
        "print(f\"Testing with raw text: '{new_review_raw[0]}'\")\n",
        "print(\"\\n...Calling the endpoint with raw text...\")\n",
        "\n",
        "try:\n",
        "    response = endpoint.predict(instances=new_review_raw)\n",
        "    print(\"\\n‚úÖ SUCCESS! Pipeline was deployed - raw text works!\")\n",
        "    print(f\"Prediction: {response.predictions}\")\n",
        "    if response.predictions[0] == 1:\n",
        "        print(\"üìä Classification: POSITIVE review ‚úì\")\n",
        "    else:\n",
        "        print(\"üìä Classification: NEGATIVE review ‚úó\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERROR: Pipeline was NOT deployed\")\n",
        "    print(f\"Error message: {str(e)}\")\n",
        "    print(\"\\nThis confirms you need to either:\")\n",
        "    print(\"1. Use the vectorizer approach (Cell 4 above) ‚úì\")\n",
        "    print(\"2. Redeploy using pipeline.joblib instead of model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e53163ab",
      "metadata": {},
      "source": [
        "## 4. Get Predictions (After Pipeline Deployment)\n",
        "\n",
        "**Use this cell AFTER deploying the complete Pipeline using the deployment notebook!**\n",
        "\n",
        "Once you've deployed `model.joblib` (which contains the pipeline), you can send raw text directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d034f93c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: 'I recently purchased this dress and I have to say, it exceeded my expectations!'\n",
            "\n",
            "...Calling endpoint...\n",
            "\n",
            "--- Prediction Result ---\n",
            "Raw prediction: 1.0\n",
            "üìä Sentiment: POSITIVE ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "## 4. Get Predictions with Raw Text (NO Vectorizer Needed!)\n",
        "\n",
        "# Single review prediction\n",
        "new_review = \"I recently purchased this dress and I have to say, it exceeded my expectations!\"\n",
        "print(f\"Review: '{new_review}'\")\n",
        "print(\"\\n...Calling endpoint...\")\n",
        "\n",
        "response = endpoint.predict(instances=[new_review])\n",
        "\n",
        "print(\"\\n--- Prediction Result ---\")\n",
        "print(f\"Raw prediction: {response.predictions[0]}\")\n",
        "\n",
        "if response.predictions[0] == 1:\n",
        "    print(\"üìä Sentiment: POSITIVE ‚úÖ\")\n",
        "else:\n",
        "    print(\"üìä Sentiment: NEGATIVE ‚ùå\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42d5b508",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing multiple reviews...\n",
            "\n",
            "================================================================================\n",
            "\n",
            "1. Review: I absolutely love this dress! The fit is perfect and the material is so soft.\n",
            "   Prediction: 1.0 ‚Üí POSITIVE ‚úÖ\n",
            "\n",
            "2. Review: The shirt shrunk after one wash. Very disappointed with the quality.\n",
            "   Prediction: -1.0 ‚Üí NEGATIVE ‚ùå\n",
            "\n",
            "3. Review: Amazing product! Highly recommend to everyone!\n",
            "   Prediction: 1.0 ‚Üí POSITIVE ‚úÖ\n",
            "\n",
            "4. Review: Terrible quality. Waste of money.\n",
            "   Prediction: -1.0 ‚Üí NEGATIVE ‚ùå\n",
            "\n",
            "5. Review: It's okay, nothing special but not bad either.\n",
            "   Prediction: -1.0 ‚Üí NEGATIVE ‚ùå\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "## Test Multiple Reviews at Once\n",
        "\n",
        "test_reviews = [\n",
        "    \"I absolutely love this dress! The fit is perfect and the material is so soft.\",\n",
        "    \"The shirt shrunk after one wash. Very disappointed with the quality.\",\n",
        "    \"Amazing product! Highly recommend to everyone!\",\n",
        "    \"Terrible quality. Waste of money.\",\n",
        "    \"It's okay, nothing special but not bad either.\"\n",
        "]\n",
        "\n",
        "print(\"Testing multiple reviews...\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, review in enumerate(test_reviews, 1):\n",
        "    response = endpoint.predict(instances=[review])\n",
        "    prediction = response.predictions[0]\n",
        "    sentiment = \"POSITIVE ‚úÖ\" if prediction == 1 else \"NEGATIVE ‚ùå\"\n",
        "\n",
        "    print(f\"\\n{i}. Review: {review}\")\n",
        "    print(f\"   Prediction: {prediction} ‚Üí {sentiment}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d96e914",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Success!\n",
        "\n",
        "**Pipeline Deployment ‡∑Ä‡∑è‡∑É‡∑í:**\n",
        "\n",
        "‚úÖ **No Vectorizer needed locally** - Pipeline ‡∂ë‡∂ö‡∑ö‡∂∏ ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è  \n",
        "‚úÖ **Send raw text directly** - `endpoint.predict(instances=[\"text\"])`  \n",
        "‚úÖ **Version control** - Vectorizer ‡∑É‡∑Ñ Model ‡∂ë‡∂ö‡∂∏ ‡∂ë‡∂ö‡∑ä‡∂ö update ‡∑Ä‡∑ô‡∂±‡∑Ä‡∑è  \n",
        "‚úÖ **Production ready** - Clean, maintainable code\n",
        "\n",
        "---\n",
        "\n",
        "### üìù Quick Reference\n",
        "\n",
        "```python\n",
        "# Single prediction\n",
        "response = endpoint.predict(instances=[\"Your review text here\"])\n",
        "print(response.predictions[0])  # 1 = Positive, -1 = Negative\n",
        "\n",
        "# Multiple predictions\n",
        "reviews = [\"review 1\", \"review 2\", \"review 3\"]\n",
        "response = endpoint.predict(instances=reviews)\n",
        "print(response.predictions)  # [1, -1, 1]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Related Notebooks\n",
        "\n",
        "- Training & Pipeline Creation: [07_Pipeline_Deployment/](../07_Pipeline_Deployment/)\n",
        "- Deployment Guide: [Deploy_Pipeline_to_Vertex_AI.ipynb](../07_Pipeline_Deployment/Deploy_Pipeline_to_Vertex_AI.ipynb)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
